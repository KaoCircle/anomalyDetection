{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File descriptions\n",
    "\n",
    "    train.csv - the training set (contains 1458644 trip records)\n",
    "    test.csv - the testing set (contains 625134 trip records)\n",
    "    sample_submission.csv - a sample submission file in the correct format\n",
    "\n",
    "### Data fields\n",
    "\n",
    "    id - a unique identifier for each trip\n",
    "    vendor_id - a code indicating the provider associated with the trip record\n",
    "    pickup_datetime - date and time when the meter was engaged\n",
    "    dropoff_datetime - date and time when the meter was disengaged\n",
    "    passenger_count - the number of passengers in the vehicle (driver entered value)\n",
    "    pickup_longitude - the longitude where the meter was engaged\n",
    "    pickup_latitude - the latitude where the meter was engaged\n",
    "    dropoff_longitude - the longitude where the meter was disengaged\n",
    "    dropoff_latitude - the latitude where the meter was disengaged\n",
    "    store_and_fwd_flag - This flag indicates whether the trip record was held in vehicle memory before sending to the vendor because the vehicle did not have a connection to the server - Y=store and forward; N=not a store and forward trip\n",
    "    trip_duration - duration of the trip in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import syslog\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing started.\n",
      "import training data. 59.66485333442688 seconds.\n",
      "0: id, 1: vendor id, 2: picktime, 3: droptime, 4: passenger count,\n",
      "5: pick longitude, 6: pick latitude, 7: drop longitude, 8: drop latitude,\n",
      "9: store and fwd flag, 10: duration\n"
     ]
    }
   ],
   "source": [
    "print('Processing started.')\n",
    "start_time = time.time()\n",
    "\n",
    "trip = []\n",
    "num = 0\n",
    "maxlogi = -200; maxlati = -200\n",
    "minlogi = 200; minlati = 200\n",
    "with open('train.csv', newline='') as csvfile:\n",
    "    R = csv.DictReader(csvfile)\n",
    "    for row in R:\n",
    "        item = []\n",
    "        item.append(int(row['id'][2:])) #0\n",
    "        item.append(int(row['vendor_id'])) #1\n",
    "        item.append(datetime.strptime(row['pickup_datetime'], \"%Y-%m-%d %H:%M:%S\")) #2\n",
    "        item.append(datetime.strptime(row['dropoff_datetime'], \"%Y-%m-%d %H:%M:%S\")) #3\n",
    "        item.append(int(row['passenger_count'])) #4\n",
    "        item.append(float(row['pickup_longitude'])) #5\n",
    "        item.append(float(row['pickup_latitude'])) #6\n",
    "        item.append(float(row['dropoff_longitude'])) #7\n",
    "        item.append(float(row['dropoff_latitude'])) #8\n",
    "        if row['store_and_fwd_flag']=='N': item.append(bool(0)) #9\n",
    "        elif row['store_and_fwd_flag']=='Y': item.append(bool(1))\n",
    "        item.append(int(row['trip_duration']))#10\n",
    "        maxlogi = max(item[5],item[7],maxlogi)\n",
    "        minlogi = min(item[5],item[7],minlogi)\n",
    "        maxlati = max(item[6],item[8],maxlati)\n",
    "        minlati = min(item[6],item[8],minlati)\n",
    "        trip.append(item)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "                                      \n",
    "print('import training data.', elapsed_time, 'seconds.')\n",
    "print('0: id, 1: vendor id, 2: picktime, 3: droptime, 4: passenger count,')\n",
    "print('5: pick longitude, 6: pick latitude, 7: drop longitude, 8: drop latitude,')\n",
    "print('9: store and fwd flag, 10: duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################REMOVE########################\n",
    "\n",
    "#longitude range: -61 to -122, latitude range: 52-32, time range: 2016-01-01 to 2016-07-01\n",
    "#print(len(trip))\n",
    "#print(row.keys())\n",
    "x_block = 5\n",
    "y_block = 2\n",
    "t_block = 183\n",
    "n_block = x_block*y_block\n",
    "n_input = n_block*n_block\n",
    "logi_len = (maxlogi-minlogi)/x_block\n",
    "lati_len = (maxlati-minlati)/y_block\n",
    "mintime = datetime.strptime('2016-1-1 0:0:0', \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def block(logi, lati):\n",
    "    x = int((logi-minlogi)/logi_len)\n",
    "    y = int((lati-minlati)/lati_len)\n",
    "    if x==x_block: x = x-1\n",
    "    if y==y_block: y = y-1\n",
    "\n",
    "    return y*x_block+x\n",
    "\n",
    "#adjacency matrice, 183*24*100\n",
    "#date from 0101 to 0107, time 0-23 stands for every hours\n",
    "#there are 10 blocks in the map, and each people traveling is counted in 10*10=100 array\n",
    "aj = np.zeros((t_block, 24, n_input))\n",
    "for t in trip:\n",
    "    orig = block(t[5], t[6])\n",
    "    dest = block(t[7], t[8])\n",
    "    date = (t[2]-mintime).days\n",
    "    time = t[2].hour\n",
    "    aj[date][time][orig+dest*n_block] += t[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create adjacency matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate adjacency matrice. 4.148188829421997 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#longitude range: -61 to -122, latitude range: 52-32, time range: 2016-01-01 to 2016-07-01\n",
    "#print(len(trip))\n",
    "#print(row.keys())\n",
    "\n",
    "w_block = 26\n",
    "mintime = datetime.strptime('2016-1-1 0:0:0', \"%Y-%m-%d %H:%M:%S\")\n",
    "logi_len = (maxlogi-minlogi)/5; lati_len = (maxlati-minlati)/2\n",
    "minlogi = minlogi+3*logi_len; maxlogi = minlogi+logi_len\n",
    "maxlati = minlati+lati_len\n",
    "\n",
    "logi_len = logi_len/3; lati_len = lati_len/3\n",
    "x_block = 3; y_block = 3\n",
    "n_block = x_block*y_block\n",
    "n_input = 100\n",
    "\n",
    "# return 0-8 and 9\n",
    "def block(logi, lati):\n",
    "    if (logi>minlogi) and (logi<maxlogi) and (lati>minlati) and (lati<maxlati):\n",
    "        x = int((logi-minlogi)/logi_len)\n",
    "        y = int((lati-minlati)/lati_len)\n",
    "        return y*x_block+x\n",
    "    else:\n",
    "        return 9\n",
    "\n",
    "#adjacency matrice, 26*7*100\n",
    "#26 weeks, 7 days\n",
    "#there are 10 blocks in the map, and each people traveling is counted in 10*10=100 array\n",
    "aj = np.zeros((26, 7, n_input))\n",
    "for t in trip:\n",
    "    orig = block(t[5], t[6])\n",
    "    dest = block(t[7], t[8])\n",
    "    date = (t[2]-mintime).days\n",
    "    week, weekday= divmod(date, 7)\n",
    "    if week<26:\n",
    "        aj[week][weekday][orig+dest*n_block] += t[4]\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('generate adjacency matrice.', elapsed_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train model. 0.9111177921295166 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# 26*7*100 to 26*20\n",
    "inpE = Input((7, n_input))\n",
    "outE = LSTM(units = 20, return_sequences=False, activation='tanh')(inpE)\n",
    "encoder = Model(inpE,outE)\n",
    "\n",
    "# 26*5 to 26*700 to 26*7*100\n",
    "inpD = Input((20,))\n",
    "outD = Reshape((20,1))(inpD)\n",
    "outD = LSTM(7*n_input,return_sequences=False, activation='tanh')(outD)\n",
    "outD = Reshape((7,n_input))(outD)\n",
    "autoencoder = Model(inpD,outD)\n",
    "\n",
    "autoencoder.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "autoencoder.fit(epochs=50,steps_per_epoch=10,batch_size=256)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print('train model.', elapsed_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "#encode\n",
    "encoderPredictions = encoder.predict(aj)\n",
    "#decode\n",
    "decoderPredictions = decoder.predict(encoderPredictions)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print('predict.', elapsed_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aj.shape, encoderPredictions.shape, decoderPredictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "aj_re = aj.reshape(-1, 700)\n",
    "\n",
    "pca = PCA(.95)\n",
    "pca_aj = pca.fit_transform(aj_re)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print('pca on adjacency matrice.', elapsed_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "pcainv_aj = pca.inverse_transform(pca_aj)\n",
    "pcainv_aj = pcainv_aj.reshape(-1, 7, 100)\n",
    "print(pcainv_aj.shape)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "start_time = time.time()\n",
    "print('pca inverse on adjacency matrice.', elapsed_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference\n",
    "\n",
    "Taxi data: https://www.kaggle.com/c/nyc-taxi-trip-duration/data\n",
    "\n",
    "Using LSTM: https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "\n",
    "https://stackoverflow.com/questions/44647258/lstm-autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resize\n",
    "normalize\n",
    "reconstruction error\n",
    "hidden layer 10\n",
    "visualize"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
